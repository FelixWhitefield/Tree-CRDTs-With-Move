\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[backend=biber, notetype=foot+end]{biblatex}
\addbibresource{bibliography.bib}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{makecell}
\usepackage{float}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[parfill]{parskip} 

\begin{document}
%TC:ignore
\begin{titlepage} % Suppresses displaying the page number on the title page and the subsequent page counts as page 1
    \newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for horizontal lines, change thickness here

    \center % Centre everything on the page

    %------------------------------------------------
    %	Headings
    %------------------------------------------------

    \textsc{\Large Electronics and Computer Science}\\[0.5cm] % Major heading such as course name

    \textsc{\large Faculty of Physical Sciences and Engineering}\\[0.5cm] % Minor heading such as course title

    \textsc{\LARGE University Of Southampton}\\[1.5cm] % Main heading such as the name of your university/college

    \begin{center}
        \large
        \textit{Author}\\
        \textsc{Felix Whitefield} % Your name
    \end{center}
    {\large \today} % Date, change the \today to a set date if you want to be precise

    \vfill

    %------------------------------------------------
    %	Title
    %------------------------------------------------

    \HRule\\[0.4cm]

    {\huge\bfseries A Study of Highly Available Move Operations in Tree CRDTs}\\[0.4cm] % Title of your document

    \HRule\\[1cm]

    %------------------------------------------------
    %	Author(s)
    %------------------------------------------------


    \vfill

    \begin{minipage}{0.45\textwidth}
        \begin{flushleft}
            \large
            \textit{Project Supervisor}\\
            Doctor \textsc{Corina Cirstea} % Your name
        \end{flushleft}
    \end{minipage}
    ~
    \begin{minipage}{0.45\textwidth}
        \begin{flushright}
            \large
            \textit{Second Examiner}\\
            Doctor \textsc{Shoaib Ehsan} % Supervisor's name
        \end{flushright}
    \end{minipage}

    % If you don't want a supervisor, uncomment the two lines below and comment the code above
    %{\large\textit{Author}}\\
    %John \textsc{Smith} % Your name

    %------------------------------------------------
    %	Date
    %------------------------------------------------

    \vfill\vfill\vfill\vfill % Position the date 3/4 down the remaining page

    A project report submitted for the award of BSc Computer Science.

    % {\large\today} % Date, change the \today to a set date if you want to be precise

    %------------------------------------------------
    %	Logo
    %------------------------------------------------

    %\vfill\vfill
    %\includegraphics[width=0.2\textwidth]{placeholder.jpg}\\[1cm] % Include a department/university logo - this will require the graphicx package

    %----------------------------------------------------------------------------------------

    \vfill % Push the date up 1/4 of the remaining page

\end{titlepage}
%TC:endignore


\newpage
%TC:ignore
% ------------------------------------- Abstract -------------------------------------------
\begin{center}
    \textsc{\large Abstract}
\end{center}

This report is an attempt to use new developments in tree CRDTs with highly available move operations to create a file synchronisation system that will resolve all directory conflicts without human interaction; and will not exhibit 'buggy' behaviour such as duplicating files which some current systems exhibit. This report should provide research into the viability of these systems in a real-world scenario. So far, this paper has reviewed the existing literature and has analysed the concurrency issues facing current systems. As well as detailing two algorithms which have been proposed that state to have solutions to the problem of creating a highly available move operation. \par
The remaining work includes creating a more refined design of the system and then implementing the separate parts to create a cohesive application. Once implemented, the system will be tested for reliability and performance. This testing will inform the final evaluation of system, where it will be compared to existing solutions.

( rewrite this whole abstract once report is finished )

%TC:endignore

% ------------------------------------- Abstract -------------------------------------------

\newpage

% STATEMENT OF ORIGINALITY ------------------------------------------------------------
%TC:ignore
\begin{center}
    \textsc{\LARGE Statement of Originality} \\ [1cm]
\end{center}
I have read and understood the ECS Academic Integrity\footnote{http://ecs.gg/ai} information and the Universityâ€™s
Academic Integrity Guidance for Students\footnote{https://www.southampton.ac.uk/quality/assessment/academic\_integrity.page}.
\\[0.3cm]
I am aware that failure to act in accordance with the Regulations Governing Academic Integrity\footnote{http://www.calendar.soton.ac.uk/sectionIV/academic-integrity-regs.html}
may lead to the imposition of penalties which, for the most serious cases, may include
termination of programme.
\\[0.3cm]
I consent to the University copying and distributing any or all of my work in any form and
using third parties (who may be based outside the EU/EEA) to verify whether my work
contains plagiarised material, and for quality assurance purposes.
\\[0.5cm]

\begin{itemize}
    \item I have acknowledged all sources, and identified any content taken from elsewhere.
    \item I have not used any resources produced by anyone else.
    \item I did all the work myself, or with my allocated group, and have not helped anyone else.
    \item The material in the report is genuine, and I have included all my data/code/designs.
    \item I have not submitted any part of this work for another assessment.
    \item My work did not involve human participants, their cells or data, or animals
\end{itemize}

% STATEMENT OF ORIGINALITY ------------------------------------------------------------


\newpage
\tableofcontents
%TC:endignore

\newpage
\section{Introduction}

\subsection{Problem}
Distributed computing systems are becoming more popular for two main reasons, availability and scalability. Distributed storage systems that have replicas need a way to merge the replicas, however, conflicts can arise when merging concurrent operations. Current software such as Google Drive and Dropbox exhibit bugs in their concurrency control when the file system is concurrently updated on different computers. This can cause different issues, such as duplication, rollbacks and unintended actions. These issues are not helpful to a user and can hinder their productivity. Also, current systems which use a client-server architecture can feel 'slow' due to the latency added by communicating with a server. These systems use a tree-like structure to represent the directory hierarchy.

\subsection{Goal}
The goal of this project is to implement and test the viability of using new advancements in tree Conflict-Free Replicated Data Types (CRDTs). CRDTs are data types that can be concurrently updated on different nodes (without any coordination), will automatically resolve any differences within the data and are eventually consistent \cite{10.1007/978-3-642-24550-3_29}.  This project aims to test the reliability (whether the system correctly resolves conflicts) and performance of the implementation. The results of these tests can be used to inform future uses of these CRDTs and should demonstrate the trade-offs of using them. The system should be able to tolerate network failures and offline usage. The implementation will be peer-to-peer, meaning that each node will be equally privileged. Another focus of this project will be on testing the throughput of the new CRDTs as, while CRDTs have naturally low latency, their conflict resolution can cause lower throughput. \par
Tree structures are used in many scenarios, so the code for this project could be used where a tree structure with a highly available move operation is wanted.

\subsection{Scope}
The scope of this project will be limited to implementing CRDTs to resolve conflicts and testing their performance and reliability. The system should be tested with a varying number of replicas and conflicts to attempt to visualize how the system would scale. Optimisations will be implemented if time allows.

\newpage
\section{Literature Review}
This research will focus on understanding current file synchronisation systems and their drawbacks; the trade-offs that come with distributed systems and their consistency models; and CRDTs and their recent developments in highly available move operations.

\subsection{Review of Existing Software}
The two main network architectures of file synchronization systems are client-server and peer-to-peer. Below I will discuss both, along with their respective drawbacks.

% File synchronisation software usually comes in two variants; either a system with a central server that handles the file sharing, or a peer-to-peer system. Each system has its own benefits and drawbacks, as described below.

\subsubsection{Client-server Systems}
A vast majority of file synchronisation systems are integrated into file backup systems. These systems store the files in the cloud and all devices will be connected and synced with the cloud's version of the files. These services usually sell themselves as 'Cloud Storage', in that your files will be backed up on the cloud and be accessible from all your devices. A few of the popular services include Google Drive\footnote{https://www.google.co.uk/intl/en-GB/drive/}, OneDrive\footnote{https://www.microsoft.com/en-us/microsoft-365/onedrive/online-cloud-storage} and Dropbox\footnote{https://www.dropbox.com/features/sync}. On these services, the conflict resolution and merge of changes is all completed on a central server. This means that all updates to the file system have to go through a single server before being relayed to interested clients. \par

This has the drawback of increased latency as all requests have to go through and be processed by the central server. If many people use the service, then the strain on the server from file transfers would be high and could increase the latency further. These systems also rely on the user trusting the provider to keep their files safe. \par

As the web evolves there is more talk about Web3\cite{WhatIsWeb3}, which has foundations in decentralisation.
\subsubsection{Peer-to-peer Systems}
There are many peer-to-peer (p2p) file-sharing programs, with many popular ones being built using the BitTorrent protocol. The most popular BitTorrent clients are uTorrent and BitTorrent\footnote{https://torrentfreak.com/utorrent-is-the-most-used-bittorrent-client-by-far-200405/}. While the BitTorrent protocol is widely used, one of its main drawbacks is that it does not accommodate editing the shared files. A modified version of the  BitTorrent protocol has been created to allow for the editing of files called Resilio\footnote{https://www.resilio.com/}. This is an improvement, however, it has some limitations and drawbacks, such as:
\begin{itemize}
    \item Renaming a folder will not rename the folder on other devices \footnote{https://help.resilio.com/hc/en-us/articles/205450655-Can-I-move-or-rename-a-syncing-folder-}.
    \item Renaming a file will cause other devices to believe it is deleted, and move the file into an archive folder. Then when the peer detects the renamed file, it will check the archive folder for a file with the same hash, and put it back with a new name\footnote{https://help.resilio.com/hc/en-us/articles/209606526-What-happens-when-file-is-renamed}.
          \begin{itemize}
              \item If the file is renamed and then changed, the hashes will not be the same and therefore will require the transmission of the whole file contents.
          \end{itemize}
\end{itemize}  \par
One drawback of peer-to-peer file sharing systems is that for the sharing to occur, at least two nodes need to be online at the same time. In comparison to a client-server architecture, where the server is always available. Also, in practice, peer-to-peer networks require some form of centralisation for the initial connection, as you cannot multicast on the web.

\subsection{Distributed Systems}
\subsubsection{The CAP Theorem}
In any distributed system that has a persistent state, such as a file system, there is a trade-off between Consistency, Availability and Partition Tolerance.
This is set out in the CAP Theorem, which was first introduced by Brewer in 2000\cite{CAPTheorem}. In this talk, Brewer stated that a distributed system could only select 2 of the 3 properties. A formal proof for the CAP theorem was provided by Gilbert and Lynch in 2002\cite{10.1145/564585.564601}, they formally defined 3 properties as follows:
\begin{itemize}
    \item \textbf{Consistency} A total order on all operations must exist such that each operation looks as if it was completed at a single instance. An equivalence being requiring requests of a distributed shared memory act as if they were executing on a single node, responding to operations one at a time.
    \item \textbf{Availability} Every request received by a non-failing node must result in a response.  This means any algorithm used by the service must eventually terminate.
    \item \textbf{Partition Tolerance} The network is allowed to lose arbitrarily many messages sent from one node to another. This can either be all the messages (full partition) or only a portion of the messages (temporary partition).
\end{itemize}
While this paper proved the CAP Theorem, further research into the area revealed that the initial CAP Theorem was too simplified. As, in reality, it is more of a trade-off between Availability and Consistency, instead of having to choose between the two. In a later paper by Brewer, "CAP Twelve Years Later: How the "Rules" Have Changed"\cite{6133253}, he explains how instead of having to choose 2 of 3 properties, different trade-offs can be made. He also explains how partitions are rare, and therefore usually Consistency or Availability would not need to be sacrificed. Only needing to make sacrifices when partitions are present. Some designers of distributed systems have misunderstood the CAP theorem and have built systems with unnecessary limitations at all times, whereas limitations are only needed in the event of failures \cite{6133253}. \par
Because the CAP Theorem is somewhat limited, a new theorem was created which takes into account new factors which better reflect the trade-offs placed on distributed systems.

\subsubsection{The PACELC Theorem}
The PACELC Theorem was proposed by Abadi \cite{6127847}, as an extension to the CAP theorem and to fill the areas in which the CAP theorem does not take into account. This theorem, therefore, creates a more complete picture of the trade-offs within distributed systems. \par
PACELC incorporates the CAP Theorem, with the first part, 'PAC', having a similar meaning: when there is a partition (P), how does the system choose between availability (A) and consitency (C). The added part, 'ELC', means: else (E), when there are no partitions, the system has to choose between latency (L) and consistency (C) \cite{6127847}. It also states that the 'ELC' part (trade-off between latency and consistency) only applies to systems that replicate data. This paper is proposing to create a PA/EL \cite{6127847} system (highly available, with low latency).

\subsection{Consistency Models}
\subsubsection{Strong and Eventual Consistency}
Most distributed data stores today are either:
\begin{itemize}
    \item \textbf{Strongly Consistent} Any subsequent read after a write will return the most recent value.
    \item \textbf{Eventually Consistent} The latest data will eventually become available, if no new updates are made.
\end{itemize}
Many databases are eventually consistent, such as Cassandra\footnote{https://cassandra.apache.org/doc/latest/cassandra/architecture/guarantees.html}. Even databases such as MongoDB\footnote{https://www.mongodb.com/docs/manual/core/read-isolation-consistency-recency/} (which, by default, is strongly consistent) will become eventually consistent when reading from secondary members. Lower consistency levels don't require the coordiniation which comes with higher levels, and therefore can achieve higher performance because of this. As the need for low latency and higher throughput increases, eventual consistency becomes more desirable over strong consistency. \par

\subsubsection{Strong Eventual Consistency}
Strong Eventual Consistency (SEC) takes eventual consistency even further, by guaranteeing that two nodes which receive the same updates (regardless of order) will be in the same state. In eventually consistent systems, the nodes would have to communicate to resolve conflicts by consensus or roll-back. Whereas in strong eventually consistent systems the conflicts are resolved in a deterministic manner on each node (without the need for communication). \par
SEC was proposed in 2011\cite{10.1007/978-3-642-24550-3_29} to describe Conflict-free Replicated Data Types (CRDTs). It was defined as:
\begin{itemize}
    \item \textbf{Strong Eventual Consistency} Eventually consistent, as well as conforming to: any two replicas that have received the same updates will have the same state.
\end{itemize}

\subsection{Logical Clocks}
Compared to physical clocks, which track time, logical clocks are used to track events. They were designed to capture the happened-before relation between events, which in turn captures causal relationships between them. The happened-before relation is denoted by "$\rightarrow$", and was defined by Lamport in 1978\cite{lamport1978time} as:
\begin{itemize}
    \item "If $a$ and $b$ are events in the same
    process, and $a$ comes before $b$, then $a$ $\rightarrow$ $b$"
\end{itemize}
This happened-before relation can be used to track the causal dependencies, as if $a$ $\rightarrow$ $b$, then $b$ is \textit{causally dependent} on $a$. Which means that $b$ may have been influenced by $a$. \par 
\subsubsection{Lamport Clocks}
Lamport clocks were created by Lamport in 1978\cite{lamport1978time}. They work by having each node maintain their own counter, which is incremented on each local event. This counter value is attached to the event, and is the lamport timestamp for that event. When nodes send messages to each other, they send their current counter value along with it. Then, the receiving node updates their counter to the received lamport timestamp if it is greater than their current counter value. It is important to note that sending and receiving messages both count as events. \par

\begin{figure}
    \centering
    \includegraphics[width=10cm]{LamportClocks.jpg}
    \caption{Example of lamport clocks. \textit{m} represents a message.}
    \label{fig:lamport}
\end{figure}

Lamport clocks give us the following guarantee, where $L(a)$ is the lamport timestamp of event $a$: 
\begin{itemize}
    \item $a \rightarrow b \implies  L(a) < L(b)$
\end{itemize}
This is useful for detecting potential causal dependencies. However, by using lamport clocks, concurrent events may appear to be causally dependent. One use for lamport clocks is to create a total order ($\prec$) which captures the causal dependencies. This can be achieved by assigning each node a unique ID, and using that to break ties when $L(a) = L(b)$. When an event happens on a node, the node ID is then also stored in the lamport timestamp. It is worth noting that this total order is arbitrary, but deterministic. This was defined by Lamport\cite{lamport1978time}, and can be denoted as:\par
\[a \prec b \iff L(a) < L(b) \lor (L(a) = L(b) \land ID(a) < ID(b))\]

\subsubsection{Vector Clocks}
Vector clocks are another logical clock that provide more gurantees than lamport clocks. Each node maintains a vector timestamp, which is a vector of counters. Each counter corresponds to a node in the system.
When an event occurs on a node, the node increments its own counter in the vector and sends the updated vector to the other nodes.
When a node receives a timestamp, it updates its own vector timestamp to be the maximum of the two timestamps. \cite{mattern1989virtual}.\par

Vector timestamps can be ordered by the following rules, where $V(a)$ is the timestamp of event $a$ and $V(a)_i$ is the value of the counter for node $i$:
\[V(a) \leq V(b) \iff \forall_i [V(a)_i \leq V(b)_i]  \]
\[V(a) = V(b) \iff \forall_i [V(a)_i = V(b)_i]\]

Lamport clocks can only indicate \emph{potential} causal dependencies. Vector timestamps are larger than Lamport timestamps, but they precisely indicate the happened-before relation between events in a system. This is denoted by the following ($\vert \vert$ denotes concurrent):

\begin{itemize}
    \item $a \rightarrow b \iff V(a) \leq V(b) \land V(a) \not = V(b)$
    \item $a = b \iff V(a) = V(b)$
    \item $a \: || \:  b \iff V(a) \not \leq V(b) \land V(b) \not \leq V(a)$
\end{itemize}

This can be used to create a partial order, as concurrent events are neither causally related nor ordered with respect to each other.

\begin{figure}
    \centering
    \includegraphics[width=10cm]{VectorClocks.jpg}
    \caption{Example of vector clocks. The first and second values correspond to nodes A and B respectively. \textit{m} represents a message.}
    \label{fig:vector}
\end{figure}

\subsection{Conflict-free Replicated Data Types}
CRDTs were created to allow for a better eventually consistent model, that can increase availability and performance while removing the need for conflict arbitration.  One main factor that allows CRDTs to guarantee SEC is that the data types are commutative\cite{10.1007/978-3-642-24550-3_29}, meaning that the updates can be applied in any order. They also do not require a main or primary elected server, as each node can resolve the conflicts by themselves. Therefore, CRDTs are applicable in a peer-to-peer environment. \par
One useful application for CRDTs is their ability for offline use \cite{10.1145/3359591.3359737}. If an application is built using CRDTs, it can feel more responsive as updates to the state can be made locally first without the system having to wait on replies from remove servers. \par
There are two main types of CRDTs, state-based and operation-based.


\subsubsection{State-Based (CvRDTs)}

\begin{figure}
    \centering
    \includegraphics[width=8cm]{state.jpg}
    \caption{State-based CRDT replication. Reproduced from \cite{10.1007/978-3-642-24550-3_29}}
    \label{fig:statebased}
\end{figure}

State-based CRDTs, or otherwise called Convergent Replicated Data Types (CvRDTs), send their full state to other replicas where they are merged by a function to form a new state. The merge function must be associative, commutative and idempotent \cite{10.1007/978-3-642-24550-3_29}. CvRDTs can use lots of bandwidth because as the state grows in size, they will still have to send the whole state. However, because they send their full state, if the transmission of a state is 'missed' it does not break the system as the next state transmission will contain all previous 'missed' updates to the state. Also, CvRDTs can make use of gossip protocols (as shown in Figure \ref{fig:statebased}) which helps reduces network usage. \par

Delta State CRDTs are a form of state-based CRDTs that only send the changed, or the delta, part of the state. This allows for the messages sent between replicas to be smaller and work across unreliable networks \cite{Almeida_2018}. They, therefore, have the best of both operation and state-based CRDTs.


\subsubsection{Operation-Based (CmRDTs)}

\begin{figure}
    \centering
    \includegraphics[width=8 cm]{operation.jpg}
    \caption{Operation-based CRDT replication. Reproduced from \cite{10.1007/978-3-642-24550-3_29}}
    \label{fig:operation}
\end{figure}

Operation-based CRDTs, or otherwise called Commutative Replicated Data Types (CmRDTs), only send the update operation to other replicas. Each operation or update is a pair consisting of a \textit{prepare} method and an \textit{effect} method. The \textit{prepare} method is executed at the local replica and produces a message representing the operation, and the \textit{effect} method applies this operation at all replicas\cite{10.1007/978-3-642-24550-3_29}. The operations also have to be commutative, but not idempotent. Because of the lack of idempotence, there are more requirements on transmission between replicas as they have to ensure each operation is sent to each replica only once (This can be seen in Figure \ref{fig:operation}). \par

\textit{Pure} operation-based CRDTs were proposed to create better operation-based CRDTs\cite{10.1007/978-3-662-43352-2_11}. These impose restrictions on the \textit{prepare} method, requiring that it does not inspect the current state and can only return the operation. They also require the state of the object to be comprised of a partially ordered log of operations. As well as defining an extension which strips causality information from operations once they are \textit{"causally stable"}\cite{10.1007/978-3-662-43352-2_11}, alllowing for the state to be smaller.

It is important to note that operation-based CRDTs are more applicable to static distributed systems, where the number of replicas is fixed. Papers about operation-based CRDTs usually assume a fixed number of replicas, such as \cite{baquero2017pure}. There are ways to make operation-based CRDTs work well in dynamic systems, such as using dotted version vectors \cite{preguiÃ§a2010dotted}. Moving forward, this paper will focus on static systems, and not dynamic systems as they are out of the scope of this paper.

\subsubsection{CRDTs and File Systems}
A file system can be represented as a tree structure, where the files and directories are the nodes and the directory hierarchy is represented by the branches between nodes. Therefore, a tree CRDT can be used to create a distributed/replicated file system that will have high availability and low latency. Tree-structured CRDTs have been created before \cite{10.1145/2757667.2757683}, \cite{kleppmann2018automerge}. However, designing a tree CRDT with a \textit{highly available} move operation poses significant challenges due to the need to preserve the strict tree invariant. \textit{Highly available} meaning: does not require locking, consensus and does not create duplicates.   \par

This can be shown by ElmerFS (A file system created using CRDTs), where concurrent moves can create a cycle \cite{10.1145/3465332.3470872}. Najafadeh et al. \cite{Najafzadeh0E18} proposes a similar system which instead locks on move operations to ensure cycles are not created. These papers show how hard creating a highly available move operation is, however recent work has shown that it is possible \cite{9563274}, \cite{https://doi.org/10.48550/arxiv.2103.04828}, \cite{https://doi.org/10.48550/arxiv.1805.04263}. \par

\subsubsection{Difficulties with Move Operations}
Tree CRDTs themselves are not difficult to implement, as shown by the paper "Abstract unordered and ordered trees CRDT" \cite{martin2012abstract} from 2012. Tree CRDTs have also been using in real-time collaborative editing applications \cite{5158449}. However, these implementations only allow for adding and removing nodes, not moving them. This is because a move operation is difficult to implement, as concurrent moves can break the tree invariant. Therefore, this section will exclusively consider conflicts that arise from move operations, as these represent new advancements in tree CRDTs. 

There are three main operations that will need to be considered when implementing conflict resolution. These being: \textit{add(p,n)}, \textit{remove(n)} and \textit{move(p,n)}. Where \textit{p} is the parent node, and \textit{n} is the globally unique id of the node to be added, removed or moved. $Add$ will add node \textit{n} under parent node \textit{p}, $remove$ will remove node \textit{n} and $move$ will move node \textit{n} to parent node \textit{p}. Considering these operations, the following describes the conflicts that can arise from concurrent operations involving move operations:

\addtocounter{footnote}{1}

\begin{itemize}
    \item
        \textit{Move-Add} conflict - This conflict has one case: 
        \begin{itemize}
            \item The move operation moves node $n_1$ with name $m$ is under node $p$, while the add operation adds node $n_2$ with name $m$ under node $p$\footnotemark[\value{footnote}]
        \end{itemize}
    \item
        \textit{Move-Remove} conflict - This conflict has two cases:
        \begin{itemize}
            \item 
                The move operation moves node $n$ under node $p$, while the remove operation removes node $p$
            \item
                The move operation moves node $n$ under node $p$, while the remove operation removes node $n$
        \end{itemize}
    \item
        \textit{Move-Move} conflict - This conflict has three cases:
        \begin{itemize}
            \item One move operation moves node $n_1$ with name $m$ under node $p$, while the other move operation moves node $n_2$ with name $m$ under node $p$\footnotemark[\value{footnote}]
            \item Two move operations move the same node $n$ to different parents $p_1$ and $p_2$
            \item One move operation moves node $n_1$ under node $n_2$, while the other move operation moves node $n_2$ under node $n_1$, creating a cycle
        \end{itemize}
\end{itemize}

\footnotetext[\value{footnote}]{This conflict will only arise if nodes are uniquely identified by their name and parent, as is typical in file systems. (However, for other systems this may not be the case)}

The conflict resolution will not be discussed here, as it will be a part of the algorithms discussed in the next section. Each algorithm will have its own conflict resolution strategy. It is important to note that the algorithms, as they are, do not uniquely identify nodes by their name and parent. And therefore, do not resolve those conflicts. These algorithms may be adapted to resolve these conflicts, and if time permits, this paper will explore such modifications.


\subsubsection{Algorithms With a Highly Available Move} \label{sssec:algorithms}
Currently, there two main proposed algorithms that allow a highly available move operation:
\begin{itemize}
    \item
          \textbf{Kleppmann et al. \cite{9563274}} proposes an algorithm that represents the tree as a set of parent-child relationships. A move operation is performed by removing the node from wherever it is in the tree and moving it to its new location. This operation can also be used for adding and removing nodes, the former by creating a new node under the specified parent and the latter by moving the node under a "trash" node. It also stores a \textit{log} of all previous operations, which allows the algorithm to implement a move operation. The algorithm can use the \textit{log} to ensure that all operations are applied in the correct order by undoing and reapplying operations (as proposed in \cite{https://doi.org/10.48550/arxiv.1805.04263}). It deals with cycles by ensuring that if any operations were to create a cycle, it would be ignored however they are still added to the \textit{log}. In general, the algorithm will prefer the latest operation that does not cause a conflict. The only conflict which the algorithm does not resolve is child nodes with the same parent having the same name.

    \item
          \textbf{Nair et al. \cite{https://doi.org/10.48550/arxiv.2103.04828}} proposes \textit{Maram}, a "light-weight" tree CRDT with a highly available move operation that represents the tree a set of nodes and child-to-parent relations. Instead of storing an in-order log of operations, this algorithm relies on a causal delivery layer which guarantees
          a happened-before relation. Maram splits move operations into \textit{down-moves} (the node is moved away from the root) and \textit{up-moves} (the node is moved towards to root or to the same distance). The conflict resolution is as follows: in concurrent up-moves, they are safe (so no conflict resolution required); in a concurrent up-move and down-move, the up-move wins; in concurrent down-moves, the move with the highest priority wins (the priority is deterministic, and specific to each application).

\end{itemize}

These will be referred to as \textit{Kleppmann's algorithm} and \textit{Maram} respectively, and will be the main focus of this paper.

Table \ref{table:differences} shows a comparison between the two algorithms:

\begin{table}[ht]
    \def\arraystretch{2}
    \caption{Comparison of Algorithms} % title of Table
    \centering % used for centering table
    \begin{tabular}{c c c} % centered columns (4 columns)
        \hline\hline %inserts double horizontal lines
                                & \textbf{Kleppmann's \cite{9563274}} & \textbf{Nair's (\textit{Maram}) \cite{https://doi.org/10.48550/arxiv.2103.04828}} \\ [0.5ex] % inserts table
        %heading
        \hline % inserts single horizontal line
        \textbf{Delivery Layer} & \makecell{Eventual Consistency                                                                                          \\ \textit{Low Cost}} & \makecell{Causal Consistency\textsuperscript{i}  \\ \textit{Higher Cost}}  \\ % inserting body of the table
        \textbf{Operation Order}     & \makecell{Total Order                                                                                                   \\ \textit{High Cost}} & \makecell{Partial Order \\ \textit{Low Cost}}

        \\ [1ex] % [1ex] adds vertical space
        \hline %inserts single line
    \end{tabular}
    \label{table:differences} % is used to refer this table in the text
\end{table}

\textsuperscript{i}\textit{Causal Consistency} gurantees that if two operations are causally related, then the second operation will be applied after the first operation on all replicas. For example, if a replica receives operation \textit{A} then creates operation \textit{B}, then operation \textit{A} should be applied before operation \textit{B} on all other replicas. \par

\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{Response.jpg}
    \caption{Response time for different conflict rates (0-20\%). Reproduced from \cite{https://doi.org/10.48550/arxiv.2103.04828}}
    \label{fig:responsetime}
\end{figure}

Figure \ref{fig:responsetime} shows differences in response times between different algorithms. Kleppmann's algorithm \cite{9563274} can be regarded as a UDR Tree, and therefore we can see that it has a slightly lower response time than Maram \cite{https://doi.org/10.48550/arxiv.2103.04828}. Figure \ref{fig:responsetime} also shows how a lower response time can be achieved by using non-locking algorithms.


This paper will use both of the algorithms stated above, Kleppmann's \cite{9563274} and Nair's (\textit{Maram}) \cite{https://doi.org/10.48550/arxiv.2103.04828}. The implementation of these algorithms, and subsequent testing, will be the main part of this project. The testing will inform the evaluation, which will compare the two algorithms and determine their viability. Notably, these algorithms require a separate delivery layer to communicate between replicas. This layer will be implemented separately from the CRDTs.


\newpage
\section{Design}
The original aim of this paper was to create a file synchronisation system using conflict-free replicated data types (CRDTs). However, due to the complexity and challenges of implementing such a system, this paper has narrowed its focus to explore the implementation and evaluation of the CRDTs. By narrowing down the scope of this research, this paper aims to provide a more in-depth analysis of the advantages and limitations of the CRDTs. This will allow for a more thorough evaluation of the CRDTs, and will allow for a more detailed comparison between the different CRDTs.

\subsection{Requirements}
The main focus of this paper is to implement the two CRDT algorithms, \cite{9563274} and \cite{https://doi.org/10.48550/arxiv.2103.04828}, and to test them individually as well as to compare them. While the evaluation of these algorithms will be the main focus, this paper will also attempt to create implementations that can be used by other developers. As such, the requirements will be as follows:
\begin{itemize}
    \item The system shall be comprised of multiple layers that can be modified independently.
    \item The system should have a simple and easy to use API.
    \item The implementations should follow the literature as closely as possible, to ensure they are logically correct.
    \item The system shall support immediate local execution of operations on the CRDTs.
    \item The replication between replicas shall be handled by a separate layer than that which handles the CRDTs. This will allow for the replication layer to be modified independently of the CRDT layer, and vice versa.
    \item The replication layer should handle the communication between replicas asynchronously.
    \item Each layer should have an interface that allows for other implementations to be created and swapped in. This will allow for the system to be easily modified and extended.
\end{itemize}

\subsection{Proposed Final Design}

The design will be split into different layers that will each be independent and can be modified separately. The layers are as follows:
\begin{itemize}
    \item \textbf{CRDT} This layer will be in charge of conflict resolution and is the main focus of this paper. The CRDTs will be implemented using the algorithms described in Section \ref{sssec:algorithms}. This layer is responsible for the following: 
        \begin{itemize}
            \item Applying operations (which will be \textit{local} or \textit{remote}) on the CRDT
            \item Resolving conflicts that arise between concurrent operations 
            \item Ensuring that all replicas eventually converge to the same state
            \item Keeping track of the state of the CRDT (the state of the tree)
            \item Providing an interface for the user to interact with the CRDT
        \end{itemize}

    \item \textbf{Consistency} This layer will be in charge of ensuring the needed consistency model (eventual consistency or causal consistency). It will need to be able to:
        \begin{itemize}
            \item Ensure that the consistency model is met, even if some replicas are offline
            \item Allow a replica to recover after being offline, and ensure that it is up-to-date with the rest of the network
        \end{itemize}
    \item \textbf{Network} This layer will be in charge of network communications. It will need to be able to:
        \begin{itemize}
            \item Connect to the peer-to-peer network
            \item \textit{Send} and \textit{Receive} file data
            \item \textit{Send} and \textit{Receive} operations
        \end{itemize}
\end{itemize}
Certain CRDTs require different consistency models, therefore the consistency layer will be dependent on the chosen CRDT. \par

\subsection{Justification of Design}
The system is decoupled into three distinct layers, which will improve the maintainability, readability and re-usability of the code. It will also help during development, as each layer will only need to focus on its own requirements. As well as allowing for each layer to be tested individually. \par

\subsection{Language and Tools}
\subsubsection{Go}
Go is a language created by Google, and is designed to be used in distributed systems with the help of its built-in, lightweight concurrency features. As this paper aims to create a distributed system, then Go is a good choice to help with this. \par

The CRDTs which will be implemented by this paper are particularly applicable to distributed file systems. Recent distributed file systems have been written using Go, such as JuiceFS or Kertish-DFS. Therefore, by using Go this paper aims to create useful implementations for these systems, or to provide a base implementation which can then be improved upon. \par

\section{Project Management}

\subsection{Account of Work to date}
The current work has been around reviewing relevant literature and creating an initial design from this research. The research has been into current systems for file synchronisation, and their drawbacks. As well as into distributed systems and consistency models. Most importantly, detailed research has been completed into CRDTs and ones applicable to this paper's proposed system. From this research, an initial design has been created outlining the main aspects of the proposed system.

\subsection{Plan of remaining work}
The design will be refined and more detailed. From this design, the CRDT layer will be implemented by first selecting an algorithm and then coding it. Then, the Network layer, where the peer-to-peer networking will be coded first, followed by operation transmission and finally file data transmission. Then, the File System layer, where the watcher (which watches the file system for changes) will be coded and then reading and writing file content. Development of these layers may overlap, but it will follow the general structure listed. \par
Once all components have been coded, the system will have its reliability and performance tested, which will inform the evaluation. The testing will seek to measure the throughput and response time of the algorithm(s), and how adding more replicas affects this. The evaluation then needs to be written and will contain the outcome of the project.

\subsection{Estimate of Support Required}
The performance testing may require the use of rented servers, to test latency.

\subsection{Gantt Chart}

\subsubsection{Completed Work}
\includegraphics[width=16cm]{completed.jpg}


\subsubsection{Remaining Work}
\begin{center}
    \includegraphics[width=16cm]{remaining.jpg}
\end{center}


\subsection{Risk Assessment}

\begin{itemize}
    \item \textbf{(P) Probability} 1 - low, 5 - high
    \item \textbf{(S) Severity}  1 - low, 5 - high
    \item \textbf{(RE) Risk Exposure} Probability * Severity
\end{itemize}

\begin{table}[ht]
    \renewcommand{\arraystretch}{1.3}
    \caption{Risk Assessment} % title of Table
    \centering % used for centering table
    \begin{tabular}{|p{3cm} | p{0.4cm} | p{0.4cm} | p{0.6cm} | p{8cm}|} % centered columns (4 columns)
        \hline\hline %inserts double horizontal lines
        \textbf{Risk}               & \textbf{P} & \textbf{S} & \textbf{RE} & \textbf{Mitigation}                                                                                              \\ [0.5ex] % inserts table
        %heading
        \hline % inserts single horizontal line
        Loss of Report              & 2          & 5          & 10          & Back-up on computer, laptop and OneDrive                                                                         \\ \hline % inserting body of the table
        Loss of Code                & 1          & 5          & 5           & Back-up on computer, laptop, OneDrive and GitHub                                                                 \\ \hline
        Underestimating Tasks       & 3          & 3          & 9           & Plan for extra time in case tasks require it, as well as making informed estimates for time needed for each task \\ \hline
        Health Issues               & 2          & 4          & 8           & Allow for spare time, and possible removal of parts of project. Attempt to not become sick.                      \\ \hline
        Implementation Difficulties & 3          & 4          & 12          & Create a clear plan of work to do, and take time to understand the design. Can seek help if needed.              \\ \hline
        Change in Scope             & 2          & 4          & 8           & Complete implementation early to allow for changes to the scope.
        \\ \hline %inserts single line
    \end{tabular}
    \label{table:risk} % is used to refer this table in the text
\end{table}


\clearpage
%TC:ignore
\printbibliography

\appendix
\section{Original Brief}
\subsection{Title}
\begin{center}
Using CRDTs to Create a File Synchronization System
\end{center}

\subsection{Problem}
Distributed computing systems are becoming more popular for two main reasons, availability
and scalability. Distributed storage systems that have replicas need a way to merge the replicas,
however conflicts can arise when merging two different replicas. Software such as Google Drive
and Dropbox exhibit bugs in their concurrency control when the filesystem is concurrently
updated on different computers. CRDTs (Conflict-free Replicated Data Types) can be
implemented to ensure strong eventual consistency (SEC) as well as remove the need for a
centralized server or leader. SEC ensures that two nodes/peers will converge to the same state
even if the order in which they receive a set of updates is different. CRDTs can have the benefit
of a low-latency because updates can be made locally without having to contact another node,
however their throughput may be lower than other solutions, such as state machines, due to
them having to resolve conflicts. Due to the high guarantees of CRDTs, implementations for
complex data types are still being theorized and tested in practice (such as tree CRDTs).

\subsection{Goal}
The goal of this project is to implement and test the performance and viability of using new
advancements in tree CRDTs in a file synchronization system to solve directory conflicts. This
project aims to be able to demonstrate whether using CRDTs in this application is viable, mainly
focusing on the throughput and reliability of the system. The system should be able to tolerate
network failures and offline usage. The implementation will be peer-to-peer, meaning that each
node will be equally privileged. Another focus of this project will be on optimisation and so
different methods will be documented to show how this was achieved, with a focus on
increasing throughput (as CRDTs have naturally low latency).
Tree structures are used in many scenarios so the code for this project could be used in other
scenarios when Strong Eventual Consistency is wanted.

\subsection{Scope}
The scope of this project will be limited to implementing CRDTs to resolve directory conflicts and
testing their performance and reliability. The system should be tested with a varying number of
replicas to attempt to visualize how the system would scale. Optimisations will only be
implemented after the system works as intended.
File conflicts will not be a focus of this project, however they could be brought into the scope if
time allows.

\subsection{Interim Abstract}
This report is an attempt to use new developments in tree CRDTs with
highly available move operations to create a file synchronisation system that
will resolve all directory conflicts without human interaction; and will not
exhibit â€™buggyâ€™ behaviour such as duplicating files which some current systems exhibit. This report should provide research into the viability of these
systems in a real-world scenario. So far, this paper has reviewed the existing
literature and has analysed the concurrency issues facing current systems. As
well as detailing two algorithms which have been proposed that state to have
solutions to the problem of creating a highly available move operation.
The remaining work includes creating a more refined design of the system and
then implementing the separate parts to create a cohesive application. Once
implemented, the system will be tested for reliability and performance. This
testing will inform the final evaluation of system, where it will be compared
to existing solutions.


%TC:endignore
\end{document}

